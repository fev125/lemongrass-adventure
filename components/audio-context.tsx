"use client"

import { createContext, useContext, useCallback, useEffect, useRef, useState, type ReactNode } from "react"

interface AudioContextType {
  playClick: () => void
  playSuccess: () => void
  playError: () => void
  speak: (text: string) => void
  stopSpeaking: () => void
  isSpeaking: boolean
  ttsAvailable: boolean
  soundEnabled: boolean
  playBgm: () => void
  stopBgm: () => void
  isBgmPlaying: boolean
}

const AudioCtx = createContext<AudioContextType | null>(null)

export function useAudio() {
  const ctx = useContext(AudioCtx)
  if (!ctx) throw new Error("useAudio must be used within AudioProvider")
  return ctx
}

interface AudioProviderProps {
  children: ReactNode
  soundEnabled: boolean
}

export function AudioProvider({ children, soundEnabled }: AudioProviderProps) {
  const audioContextRef = useRef<AudioContext | null>(null)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [ttsAvailable, setTtsAvailable] = useState(false)
  const preferredVoiceRef = useRef<SpeechSynthesisVoice | null>(null)
  const [isBgmPlaying, setIsBgmPlaying] = useState(false)
  const bgmAudioRef = useRef<HTMLAudioElement | null>(null)

  useEffect(() => {
    const initAudio = () => {
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      }
    }

    const checkTTS = () => {
      if (typeof window !== "undefined" && "speechSynthesis" in window) {
        const loadVoices = () => {
          const voices = speechSynthesis.getVoices()

          // æ—¥å¿—ï¼šè¾“å‡ºæ‰€æœ‰å¯ç”¨ä¸­æ–‡è¯­éŸ³
          const chineseVoices = voices.filter(
            (v) => v.lang.startsWith("zh-CN") || v.lang.startsWith("zh_CN") || v.lang === "zh",
          )
          console.log("[TTS] æ‰€æœ‰å¯ç”¨ä¸­æ–‡è¯­éŸ³:", chineseVoices.map((v) => ({
            name: v.name,
            lang: v.lang,
            voiceURI: v.voiceURI,
            localService: (v as any).localService,
            default: (v as any).default,
          })))

          // æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾é«˜è´¨é‡ä¸­æ–‡è¯­éŸ³
          // ä¼˜å…ˆçº§ï¼šiOS é«˜è´¨é‡è¯­éŸ³ > Chrome Google è¯­éŸ³ > å¥³å£° > å…¶ä»–æœ¬åœ°è¯­éŸ³
          const preferredVoicePatterns = [
            /tingting/i, // iOS é«˜è´¨é‡å¥³å£°
            /ting-ting/i, // macOS
            /siyi/i, // iOS é«˜è´¨é‡å¥³å£°
            /google.*æ™®é€šè¯/i, // Chrome é«˜è´¨é‡è¯­éŸ³
            /google/i, // Chrome å…¶ä»– Google è¯­éŸ³
            /microsoft.*xiaoxiao/i, // Edge å¥³å£°
            /microsoft.*yunxi/i, // Edge ç”·å£°
          ]

          let foundVoice: SpeechSynthesisVoice | null = null
          let foundReason = ""

          // å…ˆæ‰¾ä¼˜å…ˆè¯­éŸ³ï¼ˆiOS/Google ä¼˜å…ˆï¼‰ï¼Œæ”¯æŒæ­£åˆ™åŒ¹é…
          for (const pattern of preferredVoicePatterns) {
            const voice = chineseVoices.find((v) => pattern.test(v.name))
            if (voice) {
              foundVoice = voice
              foundReason = `âœ… æ‰¾åˆ°ä¼˜å…ˆè¯­éŸ³: ${voice.name} (åŒ¹é…: ${pattern})`
              break
            }
          }

          // å¦‚æžœæ²¡æ‰¾åˆ°ä¼˜å…ˆè¯­éŸ³ï¼Œå°è¯•é€‰æ‹©å¥³å£°ï¼ˆé€šå¸¸æ›´è‡ªç„¶ï¼Œé€‚åˆå„¿ç«¥åº”ç”¨ï¼‰
          if (!foundVoice) {
            // Chrome ä¸­å¥³å£°é€šå¸¸åŒ…å«ï¼šå¥³ã€femaleã€woman ç­‰å…³é”®è¯ï¼Œæˆ–æŽ’é™¤æ˜Žæ˜¾çš„ç”·å£°å…³é”®è¯
            const femaleKeywords = [/å¥³/i, /female/i, /woman/i, /xiaoxiao/i]
            const maleKeywords = [/ç”·/i, /male/i, /man/i, /eddy/i, /yunxi/i]
            
            const femaleVoices = chineseVoices.filter((v) => {
              const name = v.name.toLowerCase()
              const hasFemale = femaleKeywords.some((k) => k.test(name))
              const hasMale = maleKeywords.some((k) => k.test(name))
              return hasFemale && !hasMale
            })
            
            if (femaleVoices.length > 0) {
              const localFemale = femaleVoices.filter((v) => (v as any).localService !== false)
              foundVoice = localFemale[0] || femaleVoices[0]
              foundReason = `âœ… æ‰¾åˆ°å¥³å£°è¯­éŸ³: ${foundVoice.name} (æ›´é€‚åˆå„¿ç«¥åº”ç”¨)`
            }
          }

          // å¦‚æžœè¿˜æ²¡æ‰¾åˆ°ï¼Œä¼˜å…ˆé€‰æ‹© localService: true çš„è¯­éŸ³ï¼ˆæœ¬åœ°é«˜è´¨é‡è¯­éŸ³ï¼‰
          if (!foundVoice) {
            const localVoices = chineseVoices.filter((v) => (v as any).localService !== false)
            if (localVoices.length > 0) {
              // ä¼˜å…ˆé€‰æ‹©éžé»˜è®¤è¯­éŸ³ï¼ˆé€šå¸¸è´¨é‡æ›´å¥½ï¼‰
              foundVoice = localVoices.find((v) => !(v as any).default) || localVoices[0]
              foundReason = `âš ï¸ æœªæ‰¾åˆ°ä¼˜å…ˆè¯­éŸ³ï¼Œä½¿ç”¨æœ¬åœ°è¯­éŸ³: ${foundVoice.name}`
            } else {
              // æœ€åŽé€‰æ‹©ä»»ä½•ä¸­æ–‡è¯­éŸ³
              foundVoice = chineseVoices[0] || null
              if (foundVoice) {
                foundReason = `âš ï¸ æœªæ‰¾åˆ°æœ¬åœ°è¯­éŸ³ï¼Œä½¿ç”¨é»˜è®¤ä¸­æ–‡è¯­éŸ³: ${foundVoice.name}`
              } else {
                foundReason = `âŒ æœªæ‰¾åˆ°ä»»ä½•ä¸­æ–‡è¯­éŸ³`
              }
            }
          }

          if (foundVoice) {
            preferredVoiceRef.current = foundVoice
            setTtsAvailable(true)
            console.log(`[TTS] å·²é€‰æ‹©è¯­éŸ³:`, {
              name: foundVoice.name,
              lang: foundVoice.lang,
              voiceURI: foundVoice.voiceURI,
              localService: (foundVoice as any).localService,
              reason: foundReason,
            })
            
            // æ£€æŸ¥æ˜¯å¦æœ‰æ›´å¥½çš„è¯­éŸ³å¯ç”¨
            const betterVoices = chineseVoices.filter((v) => {
              const isPreferred = preferredVoicePatterns.some((pattern) => pattern.test(v.name))
              const isLocal = (v as any).localService !== false
              return isPreferred && isLocal && v.name !== foundVoice!.name
            })
            
            if (betterVoices.length > 0) {
              console.warn(`[TTS] âš ï¸ æ£€æµ‹åˆ°æ›´å¥½çš„è¯­éŸ³ä½†æœªä½¿ç”¨:`, betterVoices.map((v) => ({
                name: v.name,
                lang: v.lang,
                voiceURI: v.voiceURI,
                localService: (v as any).localService,
              })))
              console.warn(`[TTS] å½“å‰é€‰æ‹©åŽŸå› : ${foundReason}`)
            }
            
            // æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨è¯­éŸ³çš„å¯¹æ¯”ï¼Œå¸®åŠ©ç†è§£é€‰æ‹©
            const allLocalVoices = chineseVoices.filter((v) => (v as any).localService !== false)
            if (allLocalVoices.length > 1) {
              console.log(`[TTS] ðŸ“Š æ‰€æœ‰æœ¬åœ°ä¸­æ–‡è¯­éŸ³å¯¹æ¯” (${allLocalVoices.length}ä¸ª):`, allLocalVoices.map((v) => {
                const isPreferred = preferredVoicePatterns.some((pattern) => pattern.test(v.name))
                const isFemale = /å¥³|female|woman|xiaoxiao/i.test(v.name) && !/ç”·|male|man|eddy|yunxi/i.test(v.name)
                return {
                  name: v.name,
                  lang: v.lang,
                  isSelected: v.name === foundVoice!.name,
                  isPreferred: isPreferred ? "âœ…" : "âŒ",
                  isFemale: isFemale ? "ðŸ‘©" : "ðŸ‘¨",
                  localService: (v as any).localService,
                }
              }))
              console.log(`[TTS] ðŸ’¡ é€‰æ‹©é€»è¾‘: ä¼˜å…ˆè¯­éŸ³ > å¥³å£° > æœ¬åœ°è¯­éŸ³ > é»˜è®¤è¯­éŸ³`)
            }
          } else {
            console.error("[TTS] âŒ æœªæ‰¾åˆ°å¯ç”¨ä¸­æ–‡è¯­éŸ³")
          }
        }

        if (speechSynthesis.getVoices().length > 0) {
          loadVoices()
        }
        speechSynthesis.onvoiceschanged = loadVoices

        // è®¾ç½®è¶…æ—¶ï¼Œå¦‚æžœ3ç§’å†…æ²¡æœ‰åŠ è½½åˆ°è¯­éŸ³ï¼Œä¹Ÿæ ‡è®°ä¸ºå¯ç”¨ï¼ˆä½¿ç”¨é»˜è®¤è¯­éŸ³ï¼‰
        setTimeout(() => {
          if (!preferredVoiceRef.current && speechSynthesis.getVoices().length > 0) {
            // å°è¯•ä½¿ç”¨é»˜è®¤ä¸­æ–‡è¯­éŸ³
            const defaultVoice = speechSynthesis.getVoices().find(
              (v) => v.lang.startsWith("zh-CN") || v.lang.startsWith("zh_CN") || v.lang === "zh",
            )
            if (defaultVoice) {
              preferredVoiceRef.current = defaultVoice
              setTtsAvailable(true)
              console.log("[TTS] â° è¶…æ—¶åŽä½¿ç”¨é»˜è®¤ä¸­æ–‡è¯­éŸ³:", {
                name: defaultVoice.name,
                lang: defaultVoice.lang,
                voiceURI: defaultVoice.voiceURI,
                localService: (defaultVoice as any).localService,
              })
            } else {
              console.warn("[TTS] â° è¶…æ—¶åŽä»æœªæ‰¾åˆ°ä¸­æ–‡è¯­éŸ³")
            }
          }
        }, 3000)
      }
    }

    initAudio()
    checkTTS()

    return () => {
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  const playClick = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const oscillator = ctx.createOscillator()
    const gainNode = ctx.createGain()

    oscillator.type = "sine"
    oscillator.frequency.setValueAtTime(800, ctx.currentTime)
    oscillator.frequency.exponentialRampToValueAtTime(600, ctx.currentTime + 0.08)
    gainNode.gain.setValueAtTime(0.25, ctx.currentTime)
    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.08)

    oscillator.connect(gainNode)
    gainNode.connect(ctx.destination)

    oscillator.start(ctx.currentTime)
    oscillator.stop(ctx.currentTime + 0.08)
  }, [soundEnabled])

  const playSuccess = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const frequencies = [523.25, 659.25, 783.99, 1046.5]

    frequencies.forEach((freq, i) => {
      const oscillator = ctx.createOscillator()
      const gainNode = ctx.createGain()

      oscillator.type = "triangle"
      oscillator.frequency.setValueAtTime(freq, ctx.currentTime)
      gainNode.gain.setValueAtTime(0.2, ctx.currentTime + i * 0.12)
      gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.5 + i * 0.12)

      oscillator.connect(gainNode)
      gainNode.connect(ctx.destination)

      oscillator.start(ctx.currentTime + i * 0.12)
      oscillator.stop(ctx.currentTime + 0.6 + i * 0.12)
    })
  }, [soundEnabled])

  const playError = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const oscillator = ctx.createOscillator()
    const gainNode = ctx.createGain()

    oscillator.type = "sine"
    oscillator.frequency.setValueAtTime(300, ctx.currentTime)
    oscillator.frequency.exponentialRampToValueAtTime(200, ctx.currentTime + 0.2)
    gainNode.gain.setValueAtTime(0.15, ctx.currentTime)
    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.2)

    oscillator.connect(gainNode)
    gainNode.connect(ctx.destination)

    oscillator.start(ctx.currentTime)
    oscillator.stop(ctx.currentTime + 0.2)
  }, [soundEnabled])

  const speak = useCallback(
    (text: string) => {
      if (!soundEnabled || !ttsAvailable) return

      // åœæ­¢å½“å‰æ’­æ”¾
      speechSynthesis.cancel()

      // ä½¿ç”¨æµè§ˆå™¨æœ¬åœ° TTSï¼ˆä¼˜å…ˆ iOS é«˜è´¨é‡è¯­éŸ³ï¼‰
      const utterance = new SpeechSynthesisUtterance(text)
      
      if (preferredVoiceRef.current) {
        utterance.voice = preferredVoiceRef.current
        console.log(`[TTS] ðŸŽ¤ æ­£åœ¨ä½¿ç”¨è¯­éŸ³:`, {
          name: preferredVoiceRef.current.name,
          lang: preferredVoiceRef.current.lang,
          voiceURI: preferredVoiceRef.current.voiceURI,
          localService: (preferredVoiceRef.current as any).localService,
          text: text.substring(0, 50) + (text.length > 50 ? "..." : ""),
        })
      } else {
        console.warn("[TTS] âš ï¸ æœªè®¾ç½®è¯­éŸ³ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¯­éŸ³")
      }
      
      // è®¾ç½®è¯­éŸ³å‚æ•°ï¼Œä¼˜åŒ–æ™®é€šè¯æ•ˆæžœ
      utterance.lang = "zh-CN"
      utterance.rate = 0.9 // è¯­é€Ÿï¼ˆiOS æŽ¨èå€¼ï¼‰
      utterance.pitch = 1.1 // éŸ³è°ƒï¼ˆç•¥é«˜æ›´è‡ªç„¶ï¼‰
      utterance.volume = 1

      // çŠ¶æ€ç®¡ç†
      utterance.onstart = () => setIsSpeaking(true)
      utterance.onend = () => setIsSpeaking(false)
      utterance.onerror = (e: SpeechSynthesisErrorEvent) => {
        // "canceled" and "interrupted" are expected when we call speechSynthesis.cancel()
        if (e.error === "canceled" || e.error === "interrupted") {
          console.log("[TTS] â¹ï¸ è¯­éŸ³å·²åœæ­¢:", e.error)
        } else if (e.error === "not-allowed") {
          // ç”¨æˆ·æœªäº¤äº’æ—¶è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢ï¼Œè¿™æ˜¯æ­£å¸¸çš„
          console.log("[TTS] âš ï¸ éœ€è¦ç”¨æˆ·äº¤äº’åŽæ‰èƒ½æ’­æ”¾è¯­éŸ³")
        } else if (e.error === "synthesis-unavailable" || e.error === "voice-unavailable") {
          console.log("[TTS] âš ï¸ è¯­éŸ³åˆæˆæš‚ä¸å¯ç”¨")
        } else {
          // å…¶ä»–é”™è¯¯ï¼Œåªåœ¨æœ‰å…·ä½“é”™è¯¯ä¿¡æ¯æ—¶æ‰“å°
          if (e.error) {
            console.warn("[TTS] âš ï¸ è¯­éŸ³æ’­æ”¾å¼‚å¸¸:", e.error)
          }
        }
        setIsSpeaking(false)
      }

      speechSynthesis.speak(utterance)
    },
    [soundEnabled, ttsAvailable],
  )

  const stopSpeaking = useCallback(() => {
    speechSynthesis.cancel()
    setIsSpeaking(false)
  }, [])

  // èƒŒæ™¯éŸ³ä¹ - æ’­æ”¾ MP3 æ–‡ä»¶
  const playBgm = useCallback(() => {
    if (!soundEnabled) return

    // å¦‚æžœå·²ç»åœ¨æ’­æ”¾ï¼Œä¸é‡å¤åˆ›å»º
    if (bgmAudioRef.current && !bgmAudioRef.current.paused) return

    // åˆ›å»ºæˆ–å¤ç”¨ Audio å…ƒç´ 
    if (!bgmAudioRef.current) {
      bgmAudioRef.current = new Audio("/bgm.mp3")
      bgmAudioRef.current.loop = true
      bgmAudioRef.current.volume = 1.0 // æ­£å¸¸éŸ³é‡
      bgmAudioRef.current.muted = false // ç¡®ä¿ä¸é™éŸ³
    }

    // ç¡®ä¿ä¸é™éŸ³ï¼ˆæ¯æ¬¡æ’­æ”¾å‰æ£€æŸ¥ï¼‰
    bgmAudioRef.current.muted = false
    bgmAudioRef.current.volume = 1.0

    // æ’­æ”¾
    bgmAudioRef.current.play().then(() => {
      setIsBgmPlaying(true)
      console.log("[BGM] ðŸŽµ èƒŒæ™¯éŸ³ä¹å¼€å§‹æ’­æ”¾")
    }).catch((err) => {
      console.log("[BGM] âš ï¸ èƒŒæ™¯éŸ³ä¹æ’­æ”¾å¤±è´¥ï¼ˆéœ€è¦ç”¨æˆ·äº¤äº’ï¼‰:", err.message)
    })
  }, [soundEnabled])

  const stopBgm = useCallback(() => {
    if (bgmAudioRef.current) {
      bgmAudioRef.current.pause()
      bgmAudioRef.current.currentTime = 0
      console.log("[BGM] â¹ï¸ èƒŒæ™¯éŸ³ä¹å·²åœæ­¢")
    }
    setIsBgmPlaying(false)
  }, [])

  // è‡ªåŠ¨æ’­æ”¾èƒŒæ™¯éŸ³ä¹ï¼ˆç»„ä»¶æŒ‚è½½æ—¶ï¼‰
  useEffect(() => {
    if (soundEnabled) {
      // å»¶è¿Ÿä¸€ç‚¹æ—¶é—´ï¼Œç¡®ä¿ç»„ä»¶å®Œå…¨åˆå§‹åŒ–
      const timer = setTimeout(() => {
        playBgm()
      }, 500)
      return () => clearTimeout(timer)
    }
  }, [soundEnabled, playBgm])

  return (
    <AudioCtx.Provider
      value={{
        playClick,
        playSuccess,
        playError,
        speak,
        stopSpeaking,
        isSpeaking,
        ttsAvailable,
        soundEnabled,
        playBgm,
        stopBgm,
        isBgmPlaying,
      }}
    >
      {children}
    </AudioCtx.Provider>
  )
}
