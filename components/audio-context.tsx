"use client"

import { createContext, useContext, useCallback, useEffect, useRef, useState, type ReactNode } from "react"

interface AudioContextType {
  playClick: () => void
  playSuccess: () => void
  playError: () => void
  speak: (text: string) => void
  stopSpeaking: () => void
  isSpeaking: boolean
  ttsAvailable: boolean
  soundEnabled: boolean
  playBgm: () => void
  stopBgm: () => void
  isBgmPlaying: boolean
}

const AudioCtx = createContext<AudioContextType | null>(null)

export function useAudio() {
  const ctx = useContext(AudioCtx)
  if (!ctx) throw new Error("useAudio must be used within AudioProvider")
  return ctx
}

interface AudioProviderProps {
  children: ReactNode
  soundEnabled: boolean
}

export function AudioProvider({ children, soundEnabled }: AudioProviderProps) {
  const audioContextRef = useRef<AudioContext | null>(null)
  const [isSpeaking, setIsSpeaking] = useState(false)
  const [ttsAvailable, setTtsAvailable] = useState(false)
  const preferredVoiceRef = useRef<SpeechSynthesisVoice | null>(null)
  const [isBgmPlaying, setIsBgmPlaying] = useState(false)
  const bgmAudioRef = useRef<HTMLAudioElement | null>(null)

  // Ëá™Âä®Êí≠ÊîæËÉåÊôØÈü≥‰πê
  useEffect(() => {
    if (soundEnabled) {
      // Âª∂Ëøü‰∏ÄÁÇπÊó∂Èó¥ÔºåÁ°Æ‰øù AudioContext Â∑≤ÂàùÂßãÂåñ
      const timer = setTimeout(() => {
        playBgm()
      }, 500)
      return () => clearTimeout(timer)
    }
  }, [soundEnabled, playBgm])

  useEffect(() => {
    const initAudio = () => {
      if (!audioContextRef.current) {
        audioContextRef.current = new (window.AudioContext || (window as any).webkitAudioContext)()
      }
    }

    const checkTTS = () => {
      if (typeof window !== "undefined" && "speechSynthesis" in window) {
        const loadVoices = () => {
          const voices = speechSynthesis.getVoices()

          // Êó•ÂøóÔºöËæìÂá∫ÊâÄÊúâÂèØÁî®‰∏≠ÊñáËØ≠Èü≥
          const chineseVoices = voices.filter(
            (v) => v.lang.startsWith("zh-CN") || v.lang.startsWith("zh_CN") || v.lang === "zh",
          )
          console.log("[TTS] ÊâÄÊúâÂèØÁî®‰∏≠ÊñáËØ≠Èü≥:", chineseVoices.map((v) => ({
            name: v.name,
            lang: v.lang,
            voiceURI: v.voiceURI,
            localService: (v as any).localService,
            default: (v as any).default,
          })))

          // Êåâ‰ºòÂÖàÁ∫ßÊü•ÊâæÈ´òË¥®Èáè‰∏≠ÊñáËØ≠Èü≥
          // ‰ºòÂÖàÁ∫ßÔºöiOS È´òË¥®ÈáèËØ≠Èü≥ > Chrome Google ËØ≠Èü≥ > Â•≥Â£∞ > ÂÖ∂‰ªñÊú¨Âú∞ËØ≠Èü≥
          const preferredVoicePatterns = [
            /tingting/i, // iOS È´òË¥®ÈáèÂ•≥Â£∞
            /ting-ting/i, // macOS
            /siyi/i, // iOS È´òË¥®ÈáèÂ•≥Â£∞
            /google.*ÊôÆÈÄöËØù/i, // Chrome È´òË¥®ÈáèËØ≠Èü≥
            /google/i, // Chrome ÂÖ∂‰ªñ Google ËØ≠Èü≥
            /microsoft.*xiaoxiao/i, // Edge Â•≥Â£∞
            /microsoft.*yunxi/i, // Edge Áî∑Â£∞
          ]

          let foundVoice: SpeechSynthesisVoice | null = null
          let foundReason = ""

          // ÂÖàÊâæ‰ºòÂÖàËØ≠Èü≥ÔºàiOS/Google ‰ºòÂÖàÔºâÔºåÊîØÊåÅÊ≠£ÂàôÂåπÈÖç
          for (const pattern of preferredVoicePatterns) {
            const voice = chineseVoices.find((v) => pattern.test(v.name))
            if (voice) {
              foundVoice = voice
              foundReason = `‚úÖ ÊâæÂà∞‰ºòÂÖàËØ≠Èü≥: ${voice.name} (ÂåπÈÖç: ${pattern})`
              break
            }
          }

          // Â¶ÇÊûúÊ≤°ÊâæÂà∞‰ºòÂÖàËØ≠Èü≥ÔºåÂ∞ùËØïÈÄâÊã©Â•≥Â£∞ÔºàÈÄöÂ∏∏Êõ¥Ëá™ÁÑ∂ÔºåÈÄÇÂêàÂÑøÁ´•Â∫îÁî®Ôºâ
          if (!foundVoice) {
            // Chrome ‰∏≠Â•≥Â£∞ÈÄöÂ∏∏ÂåÖÂê´ÔºöÂ•≥„ÄÅfemale„ÄÅwoman Á≠âÂÖ≥ÈîÆËØçÔºåÊàñÊéíÈô§ÊòéÊòæÁöÑÁî∑Â£∞ÂÖ≥ÈîÆËØç
            const femaleKeywords = [/Â•≥/i, /female/i, /woman/i, /xiaoxiao/i]
            const maleKeywords = [/Áî∑/i, /male/i, /man/i, /eddy/i, /yunxi/i]
            
            const femaleVoices = chineseVoices.filter((v) => {
              const name = v.name.toLowerCase()
              const hasFemale = femaleKeywords.some((k) => k.test(name))
              const hasMale = maleKeywords.some((k) => k.test(name))
              return hasFemale && !hasMale
            })
            
            if (femaleVoices.length > 0) {
              const localFemale = femaleVoices.filter((v) => (v as any).localService !== false)
              foundVoice = localFemale[0] || femaleVoices[0]
              foundReason = `‚úÖ ÊâæÂà∞Â•≥Â£∞ËØ≠Èü≥: ${foundVoice.name} (Êõ¥ÈÄÇÂêàÂÑøÁ´•Â∫îÁî®)`
            }
          }

          // Â¶ÇÊûúËøòÊ≤°ÊâæÂà∞Ôºå‰ºòÂÖàÈÄâÊã© localService: true ÁöÑËØ≠Èü≥ÔºàÊú¨Âú∞È´òË¥®ÈáèËØ≠Èü≥Ôºâ
          if (!foundVoice) {
            const localVoices = chineseVoices.filter((v) => (v as any).localService !== false)
            if (localVoices.length > 0) {
              // ‰ºòÂÖàÈÄâÊã©ÈùûÈªòËÆ§ËØ≠Èü≥ÔºàÈÄöÂ∏∏Ë¥®ÈáèÊõ¥Â•ΩÔºâ
              foundVoice = localVoices.find((v) => !(v as any).default) || localVoices[0]
              foundReason = `‚ö†Ô∏è Êú™ÊâæÂà∞‰ºòÂÖàËØ≠Èü≥Ôºå‰ΩøÁî®Êú¨Âú∞ËØ≠Èü≥: ${foundVoice.name}`
            } else {
              // ÊúÄÂêéÈÄâÊã©‰ªª‰Ωï‰∏≠ÊñáËØ≠Èü≥
              foundVoice = chineseVoices[0] || null
              if (foundVoice) {
                foundReason = `‚ö†Ô∏è Êú™ÊâæÂà∞Êú¨Âú∞ËØ≠Èü≥Ôºå‰ΩøÁî®ÈªòËÆ§‰∏≠ÊñáËØ≠Èü≥: ${foundVoice.name}`
              } else {
                foundReason = `‚ùå Êú™ÊâæÂà∞‰ªª‰Ωï‰∏≠ÊñáËØ≠Èü≥`
              }
            }
          }

          if (foundVoice) {
            preferredVoiceRef.current = foundVoice
            setTtsAvailable(true)
            console.log(`[TTS] Â∑≤ÈÄâÊã©ËØ≠Èü≥:`, {
              name: foundVoice.name,
              lang: foundVoice.lang,
              voiceURI: foundVoice.voiceURI,
              localService: (foundVoice as any).localService,
              reason: foundReason,
            })
            
            // Ê£ÄÊü•ÊòØÂê¶ÊúâÊõ¥Â•ΩÁöÑËØ≠Èü≥ÂèØÁî®
            const betterVoices = chineseVoices.filter((v) => {
              const isPreferred = preferredVoicePatterns.some((pattern) => pattern.test(v.name))
              const isLocal = (v as any).localService !== false
              return isPreferred && isLocal && v.name !== foundVoice!.name
            })
            
            if (betterVoices.length > 0) {
              console.warn(`[TTS] ‚ö†Ô∏è Ê£ÄÊµãÂà∞Êõ¥Â•ΩÁöÑËØ≠Èü≥‰ΩÜÊú™‰ΩøÁî®:`, betterVoices.map((v) => ({
                name: v.name,
                lang: v.lang,
                voiceURI: v.voiceURI,
                localService: (v as any).localService,
              })))
              console.warn(`[TTS] ÂΩìÂâçÈÄâÊã©ÂéüÂõ†: ${foundReason}`)
            }
            
            // ÊòæÁ§∫ÊâÄÊúâÂèØÁî®ËØ≠Èü≥ÁöÑÂØπÊØîÔºåÂ∏ÆÂä©ÁêÜËß£ÈÄâÊã©
            const allLocalVoices = chineseVoices.filter((v) => (v as any).localService !== false)
            if (allLocalVoices.length > 1) {
              console.log(`[TTS] üìä ÊâÄÊúâÊú¨Âú∞‰∏≠ÊñáËØ≠Èü≥ÂØπÊØî (${allLocalVoices.length}‰∏™):`, allLocalVoices.map((v) => {
                const isPreferred = preferredVoicePatterns.some((pattern) => pattern.test(v.name))
                const isFemale = /Â•≥|female|woman|xiaoxiao/i.test(v.name) && !/Áî∑|male|man|eddy|yunxi/i.test(v.name)
                return {
                  name: v.name,
                  lang: v.lang,
                  isSelected: v.name === foundVoice!.name,
                  isPreferred: isPreferred ? "‚úÖ" : "‚ùå",
                  isFemale: isFemale ? "üë©" : "üë®",
                  localService: (v as any).localService,
                }
              }))
              console.log(`[TTS] üí° ÈÄâÊã©ÈÄªËæë: ‰ºòÂÖàËØ≠Èü≥ > Â•≥Â£∞ > Êú¨Âú∞ËØ≠Èü≥ > ÈªòËÆ§ËØ≠Èü≥`)
            }
          } else {
            console.error("[TTS] ‚ùå Êú™ÊâæÂà∞ÂèØÁî®‰∏≠ÊñáËØ≠Èü≥")
          }
        }

        if (speechSynthesis.getVoices().length > 0) {
          loadVoices()
        }
        speechSynthesis.onvoiceschanged = loadVoices

        // ËÆæÁΩÆË∂ÖÊó∂ÔºåÂ¶ÇÊûú3ÁßíÂÜÖÊ≤°ÊúâÂä†ËΩΩÂà∞ËØ≠Èü≥Ôºå‰πüÊ†áËÆ∞‰∏∫ÂèØÁî®Ôºà‰ΩøÁî®ÈªòËÆ§ËØ≠Èü≥Ôºâ
        setTimeout(() => {
          if (!preferredVoiceRef.current && speechSynthesis.getVoices().length > 0) {
            // Â∞ùËØï‰ΩøÁî®ÈªòËÆ§‰∏≠ÊñáËØ≠Èü≥
            const defaultVoice = speechSynthesis.getVoices().find(
              (v) => v.lang.startsWith("zh-CN") || v.lang.startsWith("zh_CN") || v.lang === "zh",
            )
            if (defaultVoice) {
              preferredVoiceRef.current = defaultVoice
              setTtsAvailable(true)
              console.log("[TTS] ‚è∞ Ë∂ÖÊó∂Âêé‰ΩøÁî®ÈªòËÆ§‰∏≠ÊñáËØ≠Èü≥:", {
                name: defaultVoice.name,
                lang: defaultVoice.lang,
                voiceURI: defaultVoice.voiceURI,
                localService: (defaultVoice as any).localService,
              })
            } else {
              console.warn("[TTS] ‚è∞ Ë∂ÖÊó∂Âêé‰ªçÊú™ÊâæÂà∞‰∏≠ÊñáËØ≠Èü≥")
            }
          }
        }, 3000)
      }
    }

    initAudio()
    checkTTS()

    return () => {
      if (audioContextRef.current) {
        audioContextRef.current.close()
      }
    }
  }, [])

  const playClick = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const oscillator = ctx.createOscillator()
    const gainNode = ctx.createGain()

    oscillator.type = "sine"
    oscillator.frequency.setValueAtTime(800, ctx.currentTime)
    oscillator.frequency.exponentialRampToValueAtTime(600, ctx.currentTime + 0.08)
    gainNode.gain.setValueAtTime(0.25, ctx.currentTime)
    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.08)

    oscillator.connect(gainNode)
    gainNode.connect(ctx.destination)

    oscillator.start(ctx.currentTime)
    oscillator.stop(ctx.currentTime + 0.08)
  }, [soundEnabled])

  const playSuccess = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const frequencies = [523.25, 659.25, 783.99, 1046.5]

    frequencies.forEach((freq, i) => {
      const oscillator = ctx.createOscillator()
      const gainNode = ctx.createGain()

      oscillator.type = "triangle"
      oscillator.frequency.setValueAtTime(freq, ctx.currentTime)
      gainNode.gain.setValueAtTime(0.2, ctx.currentTime + i * 0.12)
      gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.5 + i * 0.12)

      oscillator.connect(gainNode)
      gainNode.connect(ctx.destination)

      oscillator.start(ctx.currentTime + i * 0.12)
      oscillator.stop(ctx.currentTime + 0.6 + i * 0.12)
    })
  }, [soundEnabled])

  const playError = useCallback(() => {
    if (!soundEnabled || !audioContextRef.current) return

    const ctx = audioContextRef.current
    if (ctx.state === "suspended") ctx.resume()

    const oscillator = ctx.createOscillator()
    const gainNode = ctx.createGain()

    oscillator.type = "sine"
    oscillator.frequency.setValueAtTime(300, ctx.currentTime)
    oscillator.frequency.exponentialRampToValueAtTime(200, ctx.currentTime + 0.2)
    gainNode.gain.setValueAtTime(0.15, ctx.currentTime)
    gainNode.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 0.2)

    oscillator.connect(gainNode)
    gainNode.connect(ctx.destination)

    oscillator.start(ctx.currentTime)
    oscillator.stop(ctx.currentTime + 0.2)
  }, [soundEnabled])

  const speak = useCallback(
    (text: string) => {
      if (!soundEnabled || !ttsAvailable) return

      // ÂÅúÊ≠¢ÂΩìÂâçÊí≠Êîæ
      speechSynthesis.cancel()

      // ‰ΩøÁî®ÊµèËßàÂô®Êú¨Âú∞ TTSÔºà‰ºòÂÖà iOS È´òË¥®ÈáèËØ≠Èü≥Ôºâ
      const utterance = new SpeechSynthesisUtterance(text)
      
      if (preferredVoiceRef.current) {
        utterance.voice = preferredVoiceRef.current
        console.log(`[TTS] üé§ Ê≠£Âú®‰ΩøÁî®ËØ≠Èü≥:`, {
          name: preferredVoiceRef.current.name,
          lang: preferredVoiceRef.current.lang,
          voiceURI: preferredVoiceRef.current.voiceURI,
          localService: (preferredVoiceRef.current as any).localService,
          text: text.substring(0, 50) + (text.length > 50 ? "..." : ""),
        })
      } else {
        console.warn("[TTS] ‚ö†Ô∏è Êú™ËÆæÁΩÆËØ≠Èü≥ÔºåÂ∞Ü‰ΩøÁî®Á≥ªÁªüÈªòËÆ§ËØ≠Èü≥")
      }
      
      // ËÆæÁΩÆËØ≠Èü≥ÂèÇÊï∞Ôºå‰ºòÂåñÊôÆÈÄöËØùÊïàÊûú
      utterance.lang = "zh-CN"
      utterance.rate = 0.9 // ËØ≠ÈÄüÔºàiOS Êé®ËçêÂÄºÔºâ
      utterance.pitch = 1.1 // Èü≥Ë∞ÉÔºàÁï•È´òÊõ¥Ëá™ÁÑ∂Ôºâ
      utterance.volume = 1

      // Áä∂ÊÄÅÁÆ°ÁêÜ
      utterance.onstart = () => setIsSpeaking(true)
      utterance.onend = () => setIsSpeaking(false)
      utterance.onerror = (e: SpeechSynthesisErrorEvent) => {
        // "canceled" and "interrupted" are expected when we call speechSynthesis.cancel()
        if (e.error === "canceled" || e.error === "interrupted") {
          console.log("[TTS] ‚èπÔ∏è ËØ≠Èü≥Â∑≤ÂÅúÊ≠¢:", e.error)
        } else if (e.error === "not-allowed") {
          // Áî®Êà∑Êú™‰∫§‰∫íÊó∂Ëá™Âä®Êí≠ÊîæË¢´ÈòªÊ≠¢ÔºåËøôÊòØÊ≠£Â∏∏ÁöÑ
          console.log("[TTS] ‚ö†Ô∏è ÈúÄË¶ÅÁî®Êà∑‰∫§‰∫íÂêéÊâçËÉΩÊí≠ÊîæËØ≠Èü≥")
        } else if (e.error === "synthesis-unavailable" || e.error === "voice-unavailable") {
          console.log("[TTS] ‚ö†Ô∏è ËØ≠Èü≥ÂêàÊàêÊöÇ‰∏çÂèØÁî®")
        } else {
          // ÂÖ∂‰ªñÈîôËØØÔºåÂè™Âú®ÊúâÂÖ∑‰ΩìÈîôËØØ‰ø°ÊÅØÊó∂ÊâìÂç∞
          if (e.error) {
            console.warn("[TTS] ‚ö†Ô∏è ËØ≠Èü≥Êí≠ÊîæÂºÇÂ∏∏:", e.error)
          }
        }
        setIsSpeaking(false)
      }

      speechSynthesis.speak(utterance)
    },
    [soundEnabled, ttsAvailable],
  )

  const stopSpeaking = useCallback(() => {
    speechSynthesis.cancel()
    setIsSpeaking(false)
  }, [])

  // ËÉåÊôØÈü≥‰πê - Êí≠Êîæ MP3 Êñá‰ª∂
  const playBgm = useCallback(() => {
    if (!soundEnabled) return

    // Â¶ÇÊûúÂ∑≤ÁªèÂú®Êí≠ÊîæÔºå‰∏çÈáçÂ§çÂàõÂª∫
    if (bgmAudioRef.current && !bgmAudioRef.current.paused) return

    // ÂàõÂª∫ÊàñÂ§çÁî® Audio ÂÖÉÁ¥†
    if (!bgmAudioRef.current) {
      bgmAudioRef.current = new Audio("/bgm.mp3")
      bgmAudioRef.current.loop = true
      bgmAudioRef.current.volume = 1.0 // Ê≠£Â∏∏Èü≥Èáè
    }

    // Êí≠Êîæ
    bgmAudioRef.current.play().then(() => {
      setIsBgmPlaying(true)
      console.log("[BGM] üéµ ËÉåÊôØÈü≥‰πêÂºÄÂßãÊí≠Êîæ")
    }).catch((err) => {
      console.log("[BGM] ‚ö†Ô∏è ËÉåÊôØÈü≥‰πêÊí≠ÊîæÂ§±Ë¥•ÔºàÈúÄË¶ÅÁî®Êà∑‰∫§‰∫íÔºâ:", err.message)
    })
  }, [soundEnabled])

  const stopBgm = useCallback(() => {
    if (bgmAudioRef.current) {
      bgmAudioRef.current.pause()
      bgmAudioRef.current.currentTime = 0
      console.log("[BGM] ‚èπÔ∏è ËÉåÊôØÈü≥‰πêÂ∑≤ÂÅúÊ≠¢")
    }
    setIsBgmPlaying(false)
  }, [])

  return (
    <AudioCtx.Provider
      value={{
        playClick,
        playSuccess,
        playError,
        speak,
        stopSpeaking,
        isSpeaking,
        ttsAvailable,
        soundEnabled,
        playBgm,
        stopBgm,
        isBgmPlaying,
      }}
    >
      {children}
    </AudioCtx.Provider>
  )
}
